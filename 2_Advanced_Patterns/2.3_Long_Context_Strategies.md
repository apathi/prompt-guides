# 2.3 Long‚ÄëContext Strategies

- Put **instructions first**, repeat key constraints at end; segment with headings/tags; keep examples short and consistent. [A7][A2]

## üîç Why Long-Context Is Challenging

- **Attention dilution**: As context length grows, models may forget instructions buried in the middle.
- **Instruction bleed**: Without clear boundaries, examples or irrelevant content can get mistaken for instructions.
- **Output drift**: Inconsistencies creep in if examples vary in length/format.

---

## üìã Key Tactics (Expanded)

### **A. Put instructions first**
- Models weight **earlier tokens more heavily** in long prompts.
- Start with:
	- **Goal statement** (what to do, who the audience is).
	- **Constraints** (length, style, format).
	- **Safety rules** (refusals, source usage).
- Reinforce at the end (bookending).
- Example:
	```typescript
	<instructions>
	Task: Summarize quarterly report for executives.
	Constraints: ‚â§5 bullets, ‚â§12 words each, no financial projections.
	Safety: Never speculate; if missing data, say "Not reported."
	</instructions>

	<context>
	... 30 pages of quarterly report ...
	</context>

	<reminder>
	Repeat: ‚â§5 bullets, ‚â§12 words, no projections.
	</reminder>
	```

### **B. Repeat key constraints at the end**
- "Recency bias" means models often pay more attention to the last part of a prompt.
- Use a **closing block** (like \<reminder\> above) to restate must-follow rules.

---

### **C. Segment with headings or tags**
- Separate *instructions*, *context*, *examples*, and *format*.
- Helps the model know *what is instruction vs what is content*.
- Works with **XML tags**, ### Headings, or fences (---).

Example:
```typescript
<instructions>...</instructions>
<examples>...</examples>
<context>...</context>
<format>...</format>
```

### **D. Keep examples short and consistent**
- Long, varied few-shot examples eat context budget and confuse the model.
- Use **minimal pairs**: same format, same length, one clear difference.
- Example (classification):

```typescript
<examples>
Input: "Login fails after 3 attempts"
Output: {"category":"bug","severity":"high"}

Input: "Add dark mode"
Output: {"category":"feature","severity":"low"}
</examples>
```

### **E. Chunk large documents**
- For **\>20k tokens** of context, don't feed everything at once.
- Instead:
	- Summarize each section separately.
	- Or use retrieval (RAG) to select relevant chunks.
- Example:

```typescript
Step 1: Split 100-page doc into 10-page segments.
Step 2: Summarize each (‚â§200 words).
Step 3: Merge summaries into final executive brief.
```

### **D. Track state with tags**
- For long workflows, mark sections with \<state\> or \<step\> tags so the model doesn't lose track.
- Example:

```typescript
<step>Plan: Extract KPIs first</step>
<step>Next: Highlight anomalies</step>
```

## ‚öñÔ∏è Why This Works

- **Instructions first**: front-loads the task definition.
- **Repeat at end**: leverages recency bias.
- **Headings/tags**: reduce bleed and drift.
- **Short examples**: preserve tokens, reduce confusion.
- **Chunking**: avoids overwhelming context window.
- **State tags**: make long multi-turn flows coherent.

---

## üõ†Ô∏è Best Practices

1. **Bookend critical rules** (front + back).
2. **Delimit clearly** (\<instructions\>, \<context\>, \<reminder\>).
3. **Standardize examples** (short, uniform).
4. **Use RAG/sectional summarization** for very long docs.
5. **Audit outputs** with eval sets that mirror long-context use cases.

---

‚úÖ In short: Long-context prompting is about **signal boosting** ‚Äî making sure instructions aren't lost in the noise of a giant prompt.