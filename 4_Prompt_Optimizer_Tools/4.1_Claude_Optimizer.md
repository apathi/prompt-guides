# 4.1 Claude Prompt Optimizer

Claude provides a set of interactive tools to improve, evaluate, and debug prompts directly inside the Claude Console.

- **Key Docs:**
	- [Prompt Engineering Guide](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/prompt-improver) – Best practices + prompt improvement methods [A14]
	- [Evaluation Tool](https://docs.claude.com/en/docs/test-and-evaluate/eval-tool#creating-test-cases) – Evaluating prompts using Claude's eval system [A15]
- **Tool Links:**
	- [Claude Console](https://console.anthropic.com/) – Central dashboard for all tools [ A16]
	- [Claude Workbench](https://console.anthropic.com/workbench/) – Workspace to test and refine prompts [A17]

### Step-by-Step Instructions
1. Open the [Claude Console](https://console.anthropic.com/)
2. Click **Workbench** to create or import a prompt
3. Paste your prompt and any relevant inputs
4. Use the **Prompt Improver** button to auto-refine based on best practices
5. Save variants and test side-by-side using Claude's native output comparison

### Evaluating Your Prompt
- **Documentation:** [Evaluation Tool Docs](https://docs.claude.com/en/docs/test-and-evaluate/eval-tool#creating-test-cases) – Create test cases and structured evaluations
1. Navigate to the **Evaluate** tab in the Console
2. Define multiple input cases (e.g., edge cases, tricky examples)
3. Create evaluation criteria: factual accuracy, format, tone, safety, etc.
4. Run prompt versions across cases
5. View pass/fail and score breakdowns to iterate effectively